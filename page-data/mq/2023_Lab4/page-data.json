{
    "componentChunkName": "component---src-pages-mq-2023-lab-4-index-md",
    "path": "/mq/2023_Lab4/",
    "result": {"pageContext":{"frontmatter":{"title":"Lab 3 - Deploy an MQ Uniform Cluster on CP4I"},"relativePagePath":"/mq/2023_Lab4/index.md","titleType":"page","MdxNode":{"id":"1de7dba7-0298-531c-8753-6ab824421e10","children":[],"parent":"88cb096f-9c8e-5e6e-8d35-598c22630ee4","internal":{"content":"---\ntitle: Lab 3 - Deploy an MQ Uniform Cluster on CP4I\n---\n[Return to main lab page](../../MQ-Labs/Overview/)\n\n## Configure and deploy an MQ Uniform cluster in CloudPak for Integration.\n\nIn this lab you will deploy an MQ Uniform Cluster in CP4I. The MQ Operator is not \"uniform cluster aware\" but you can easily configure a uniform cluster by providing INI and MQSC files to new queue managers deployed by the operator.\n\n* #NOTE: PRE-REQUISITE\n  Make sure that you have an MQ Client installed in your local machine.\n  They can be downloaded from:\n\n  - Windows:\n    https://www.ibm.com/support/fixcentral/swg/doSelectFixes?options.selectedFixes=9.3.0.0-IBM-MQC-Win64&continue=1\n  - Linux:\n    https://www.ibm.com/support/fixcentral/swg/doSelectFixes?options.selectedFixes=9.3.0.0-IBM-MQC-LinuxX64&continue=1\n  - MacOS\n    https://developer.ibm.com/tutorials/mq-macos-dev/\n\n    Follow any configuration instructions of the mq client after installation.\n\n1. Log into the OCP console\n2. Click on the (+) icon at the top right of the Openshift console and paste the contents of the configmap-unicluster-ini.yaml file included in this lab.\n\n![](images/1_ocpconsole_newfile.png)\n\n3. Replace the namespace with your namespace (e.g. \"cody01\") and also replace it in the Conname parameter values and then click Create.\n\n![](images/2_change_namespace.png)\n\n4. Click the plus sign once more to import the configmap-unicluster-qm1-mqsc.yaml file as shown in the following screenshot.\n\n![](images/3_importmqsc.png)\n\n5. Replace the namespace with your own namespace and also place it in the CONNAME parameter within the MQSC file.\n\n![](images/4_replacenamespamqsc.png)\n\n6. Repeat the same process to import the configmap-unicluster-qm2-mqsc.yaml and configmap-unicluster-qm3-mqsc.yaml files.\n7. After clicking on Configmaps under the Workloads section in the left menu bar you should see the configmaps that where created by importing the files\n\n![](images/5_allconfigmaps.png)\n\n8. Switch to the Platform Navigator console, log in and then click on Integration Instances.\n\n![](images/6_integrationinstances.png)\n\n9. Click on Create an Instance.\n\n![](images/7_createii.png)\n\n10. Click on Messaging.\n\n![](images/8_messagingnext.png)\n\n11. Click on QuickStart\n\n![](images/9_quickstart.png)\n\n12. Type unicluster-qm1 as name, accept the license and toggle the Advanced Settings switch.\n\n![](images/10_namelicense.png)\n\n13. Scroll down to the INI section. Click on Add+ to add items to the section. Type AutoCluster.ini in the Advanced:Items text box and press Enter. A gray bouble shoud appear arund the text). Then select unicluster-ini in the Advanced:Name selection box.\n\n![](images/11_uniclusterini.png)\n\n14. Scroll further down into the MQSC section and click on Add+. Type UniCluster.mqsc in the Advanced:Items section and press Enter and then select unicluster-qm1-mqsc in the Advanced:Name selection box. Finally, type QM1 as the queue manager name and click create on the top right\n\n![](images/12_mqsc.png)\n\n15. Repeat the process for another queue manager called QM2. Make sure you select the corresponding mqsc configmap.\n16. You should end up with two running queue managers.\n\n![](images/13_2qm.png)\n\nThe INI and MQSC cofigmaps you provided included the configuration so that a Uniform cluster is created between both queue managers. Unlike traditional MQ queue managers where you have to select a couple a full repositories and then manually create channels and add additional queue managers by starting the channeles, a Uniform Cluster has automatic dynamic configuration. New queue mananagers just need to boot up and they will be automatically added to the cluster.\n\n17. Go back to the OCP console. Under workloads select pods and type Uni in the filter text box.\n    You should see the two queue managers running. Click on the first queue manager.\n\n![](images/14_qmpods.png)\n\n19. Click on Terminal\n\n![](images/15_terminal.png)\n\n20. Type runmqsc and then type DISPLAY QMGR REPOS\n\n![](images/16d_displayrepo.png)\n\nIt will show that that queue manager is a full repository for a cluster called UNICLUSTER (which was defined in the INI file)\n\n20. Type DISPLAY CHANNEL(UNI*)\n\n![](images/17_displaychannel.png)\n\nIt will show a Cluster receiever and a cluster sender channel. Those are the channels connecting the two queue managers.\n\n21. Repeat the queue manager creation process once again in the Platform Navigator console but for a queue manager called QM3. Make sure you select the corresponding mqsc configmap when required.\n22. Go back to the OCP console and select Pods. You should now see 3 pods.\n\n![](images/18_3qms.png)\n\n23. Click on the qm3 pod and go into the terminal\n24. Type runmqsc and then type DISPLAY QMGR REPOS and then DISPLAY CHANNEL(UNI*)\n\n![](images/19_displayrepo.png)\n\nYou will see that now the REPOS parameter is empty. This is because the new queue manager is not a ful repository for the cluster. You will also see that now there are 3 channels. One cluster receiver with its name and two cluster senders connecting it to the other two queue managers.\n\nNow we will allow external connectivity into the cluster so that you can connect an mq client running in your laptop to the queue manager uniform cluster.\nOn Lab #2 we created an OCP route and TLS on MQ to connect to the queue manager. Now we are going to take another approach. We will be creating a LoadBalancer object and will not be using TLS.\n\nWith this approach each queue manager will have its own external IP address. Even though we will be creating a LoadBalancer there will be no loadbalacing performed by an external load balancer into the pods as each queue manager pod is unique. It is the quemanagers themselves who balance the client connections in to them once a client connects to any of them. The client is aware of the ip addresses of each queue manager by using a CCDT file.\n\n25. Import the  unicluster-qm1-lb.yaml, unicluster-qm2-lb.yaml and unicluster-qm1-lb.yaml files\n\n![](images/20_importlbyaml.png)\n\n26. In the OCP console click on services within the Networking section in the left menu and type -lb in the filter text box. Click on the unicluster-qm1-lb service.\n\n![](images/21_lblist.png)\n\n27. You will see that it has an external IP address assigned. Take note of it.\n\n![](images/22_getip.png)\n\nDo the same to get the ip address of the unicluster-qm2-lb service.\n\n28. Edit the ibm-mq-ccdt.json file and replace the two exiting IP addresses with the two ip address you got from your service instances. Note that they are repeated once more. This is because the client shoudl be able to  connect by either providing a specific queue manager name (with no load balancing nor failover) or providing a wildcard name.\n\n![](images/23_ccdt.png)\n\n29. In your laptop open a new terminal window and run the following commands replacing \"*path-to-ccdt*\" with the folders where you downloaded the ibm-mq-ccdt.json file:\n    Note: If your laptop is running MacOS Catalina or later run the bash command. This is because the fault command shell (zsh) has issues when typing \"*\" as part of command.\n\n![](images/24_bashexport.png)\n\n```\nexport MQCCDTURL='/path-to-ccdt/ibm-mq-ccdt.json'\n```\n\n30. Run the follwing command in the terminal window:\n\n    ```\n    amqsputc Q1 *ANY_QM\n    ```\n\n    The sample program amsputc will put the messages to queue **Q1** . These messages should still be available after a failover.\n    Type a few messages and press Enter after each one. Type another message and press Enter twice to disconnect from the queue manager.\n\n![](images/25_amqsput.png)\n\n\n31. Go back to Platform Navigator and into the Intgration Instances section. Click on the unicluster-qm1 queue manager.\n\n![](images/26_clickinstance.png)\n\n\n32. Click on Queues\n\n![](images/27_queues.png)\n\n\n33. Check the queue depth of Q1. It should show the number of messages you sent from the command line using amqsputc.\n\n![](images/28_curpdeth.png)\n\n34. Go back to the OCP console, click in statefulsets within the Workloads section of the left menu, type Uni in the filter text box and click on the unicluster-qm1-ibm-mq statefulset\n\n![](images/29_statefulset.png)\n\n35. Click on the down arrow next to the wheel to scale down the statefulset to 0 pods.\n\n![](images/30_scaledown.png)\n\n\n36. Return to the terminal window on your browser and put more messages.\n\n![](images/31_put2.png)\n\n```\namqsputc Q1 *ANY_QM\n```\n\n\n37. Return the Platform Navigator intgration instances. You should see that unicluster-qm1 shows an error because we removed all pods. Click on unicluster-qm2.\n\n![](images/32_qmlist2.png)\n\n38. Click on Queues.\n\n![](images/33_queues.png)\n\n39. Check the queue depth of Q1. It should show the number of messages you sent from the command line using amqsputc. It should show the number of messages you put the second time.\n\nQ1 exists on all 3 queue managers. Unlike Lab #1 these queue managers are not replicas of each other for HA purposes. They equal but independent queue managers. The MQ client successfuly failed over to the second queue manager when the first went down but each queue manager has itÂ´s own set of messages. If more clients were to be connected the connections will get load balanced across all queue managers. Unifom clusters provide scaling/load balacing and continuos avaibility for new transactions. It can be combined with MQ Native HA so that data HA is provided as well. In that case each of the members of the Uniform cluster will have 2 additional passive pods.\n\n## Congratulations\n\nYou have completed this lab for MQ Uniform clusters on CP4I.\n\n## Chalenge\n\nCombine all 3 MQ labs: Add Native HA to the Uniform Cluster members and configure OCP routes and TLS for each of the queue managers.\n","type":"Mdx","contentDigest":"607d06f8627dc8c4d559bd2dcf366504","owner":"gatsby-plugin-mdx","counter":1487},"frontmatter":{"title":"Lab 3 - Deploy an MQ Uniform Cluster on CP4I"},"exports":{},"rawBody":"---\ntitle: Lab 3 - Deploy an MQ Uniform Cluster on CP4I\n---\n[Return to main lab page](../../MQ-Labs/Overview/)\n\n## Configure and deploy an MQ Uniform cluster in CloudPak for Integration.\n\nIn this lab you will deploy an MQ Uniform Cluster in CP4I. The MQ Operator is not \"uniform cluster aware\" but you can easily configure a uniform cluster by providing INI and MQSC files to new queue managers deployed by the operator.\n\n* #NOTE: PRE-REQUISITE\n  Make sure that you have an MQ Client installed in your local machine.\n  They can be downloaded from:\n\n  - Windows:\n    https://www.ibm.com/support/fixcentral/swg/doSelectFixes?options.selectedFixes=9.3.0.0-IBM-MQC-Win64&continue=1\n  - Linux:\n    https://www.ibm.com/support/fixcentral/swg/doSelectFixes?options.selectedFixes=9.3.0.0-IBM-MQC-LinuxX64&continue=1\n  - MacOS\n    https://developer.ibm.com/tutorials/mq-macos-dev/\n\n    Follow any configuration instructions of the mq client after installation.\n\n1. Log into the OCP console\n2. Click on the (+) icon at the top right of the Openshift console and paste the contents of the configmap-unicluster-ini.yaml file included in this lab.\n\n![](images/1_ocpconsole_newfile.png)\n\n3. Replace the namespace with your namespace (e.g. \"cody01\") and also replace it in the Conname parameter values and then click Create.\n\n![](images/2_change_namespace.png)\n\n4. Click the plus sign once more to import the configmap-unicluster-qm1-mqsc.yaml file as shown in the following screenshot.\n\n![](images/3_importmqsc.png)\n\n5. Replace the namespace with your own namespace and also place it in the CONNAME parameter within the MQSC file.\n\n![](images/4_replacenamespamqsc.png)\n\n6. Repeat the same process to import the configmap-unicluster-qm2-mqsc.yaml and configmap-unicluster-qm3-mqsc.yaml files.\n7. After clicking on Configmaps under the Workloads section in the left menu bar you should see the configmaps that where created by importing the files\n\n![](images/5_allconfigmaps.png)\n\n8. Switch to the Platform Navigator console, log in and then click on Integration Instances.\n\n![](images/6_integrationinstances.png)\n\n9. Click on Create an Instance.\n\n![](images/7_createii.png)\n\n10. Click on Messaging.\n\n![](images/8_messagingnext.png)\n\n11. Click on QuickStart\n\n![](images/9_quickstart.png)\n\n12. Type unicluster-qm1 as name, accept the license and toggle the Advanced Settings switch.\n\n![](images/10_namelicense.png)\n\n13. Scroll down to the INI section. Click on Add+ to add items to the section. Type AutoCluster.ini in the Advanced:Items text box and press Enter. A gray bouble shoud appear arund the text). Then select unicluster-ini in the Advanced:Name selection box.\n\n![](images/11_uniclusterini.png)\n\n14. Scroll further down into the MQSC section and click on Add+. Type UniCluster.mqsc in the Advanced:Items section and press Enter and then select unicluster-qm1-mqsc in the Advanced:Name selection box. Finally, type QM1 as the queue manager name and click create on the top right\n\n![](images/12_mqsc.png)\n\n15. Repeat the process for another queue manager called QM2. Make sure you select the corresponding mqsc configmap.\n16. You should end up with two running queue managers.\n\n![](images/13_2qm.png)\n\nThe INI and MQSC cofigmaps you provided included the configuration so that a Uniform cluster is created between both queue managers. Unlike traditional MQ queue managers where you have to select a couple a full repositories and then manually create channels and add additional queue managers by starting the channeles, a Uniform Cluster has automatic dynamic configuration. New queue mananagers just need to boot up and they will be automatically added to the cluster.\n\n17. Go back to the OCP console. Under workloads select pods and type Uni in the filter text box.\n    You should see the two queue managers running. Click on the first queue manager.\n\n![](images/14_qmpods.png)\n\n19. Click on Terminal\n\n![](images/15_terminal.png)\n\n20. Type runmqsc and then type DISPLAY QMGR REPOS\n\n![](images/16d_displayrepo.png)\n\nIt will show that that queue manager is a full repository for a cluster called UNICLUSTER (which was defined in the INI file)\n\n20. Type DISPLAY CHANNEL(UNI*)\n\n![](images/17_displaychannel.png)\n\nIt will show a Cluster receiever and a cluster sender channel. Those are the channels connecting the two queue managers.\n\n21. Repeat the queue manager creation process once again in the Platform Navigator console but for a queue manager called QM3. Make sure you select the corresponding mqsc configmap when required.\n22. Go back to the OCP console and select Pods. You should now see 3 pods.\n\n![](images/18_3qms.png)\n\n23. Click on the qm3 pod and go into the terminal\n24. Type runmqsc and then type DISPLAY QMGR REPOS and then DISPLAY CHANNEL(UNI*)\n\n![](images/19_displayrepo.png)\n\nYou will see that now the REPOS parameter is empty. This is because the new queue manager is not a ful repository for the cluster. You will also see that now there are 3 channels. One cluster receiver with its name and two cluster senders connecting it to the other two queue managers.\n\nNow we will allow external connectivity into the cluster so that you can connect an mq client running in your laptop to the queue manager uniform cluster.\nOn Lab #2 we created an OCP route and TLS on MQ to connect to the queue manager. Now we are going to take another approach. We will be creating a LoadBalancer object and will not be using TLS.\n\nWith this approach each queue manager will have its own external IP address. Even though we will be creating a LoadBalancer there will be no loadbalacing performed by an external load balancer into the pods as each queue manager pod is unique. It is the quemanagers themselves who balance the client connections in to them once a client connects to any of them. The client is aware of the ip addresses of each queue manager by using a CCDT file.\n\n25. Import the  unicluster-qm1-lb.yaml, unicluster-qm2-lb.yaml and unicluster-qm1-lb.yaml files\n\n![](images/20_importlbyaml.png)\n\n26. In the OCP console click on services within the Networking section in the left menu and type -lb in the filter text box. Click on the unicluster-qm1-lb service.\n\n![](images/21_lblist.png)\n\n27. You will see that it has an external IP address assigned. Take note of it.\n\n![](images/22_getip.png)\n\nDo the same to get the ip address of the unicluster-qm2-lb service.\n\n28. Edit the ibm-mq-ccdt.json file and replace the two exiting IP addresses with the two ip address you got from your service instances. Note that they are repeated once more. This is because the client shoudl be able to  connect by either providing a specific queue manager name (with no load balancing nor failover) or providing a wildcard name.\n\n![](images/23_ccdt.png)\n\n29. In your laptop open a new terminal window and run the following commands replacing \"*path-to-ccdt*\" with the folders where you downloaded the ibm-mq-ccdt.json file:\n    Note: If your laptop is running MacOS Catalina or later run the bash command. This is because the fault command shell (zsh) has issues when typing \"*\" as part of command.\n\n![](images/24_bashexport.png)\n\n```\nexport MQCCDTURL='/path-to-ccdt/ibm-mq-ccdt.json'\n```\n\n30. Run the follwing command in the terminal window:\n\n    ```\n    amqsputc Q1 *ANY_QM\n    ```\n\n    The sample program amsputc will put the messages to queue **Q1** . These messages should still be available after a failover.\n    Type a few messages and press Enter after each one. Type another message and press Enter twice to disconnect from the queue manager.\n\n![](images/25_amqsput.png)\n\n\n31. Go back to Platform Navigator and into the Intgration Instances section. Click on the unicluster-qm1 queue manager.\n\n![](images/26_clickinstance.png)\n\n\n32. Click on Queues\n\n![](images/27_queues.png)\n\n\n33. Check the queue depth of Q1. It should show the number of messages you sent from the command line using amqsputc.\n\n![](images/28_curpdeth.png)\n\n34. Go back to the OCP console, click in statefulsets within the Workloads section of the left menu, type Uni in the filter text box and click on the unicluster-qm1-ibm-mq statefulset\n\n![](images/29_statefulset.png)\n\n35. Click on the down arrow next to the wheel to scale down the statefulset to 0 pods.\n\n![](images/30_scaledown.png)\n\n\n36. Return to the terminal window on your browser and put more messages.\n\n![](images/31_put2.png)\n\n```\namqsputc Q1 *ANY_QM\n```\n\n\n37. Return the Platform Navigator intgration instances. You should see that unicluster-qm1 shows an error because we removed all pods. Click on unicluster-qm2.\n\n![](images/32_qmlist2.png)\n\n38. Click on Queues.\n\n![](images/33_queues.png)\n\n39. Check the queue depth of Q1. It should show the number of messages you sent from the command line using amqsputc. It should show the number of messages you put the second time.\n\nQ1 exists on all 3 queue managers. Unlike Lab #1 these queue managers are not replicas of each other for HA purposes. They equal but independent queue managers. The MQ client successfuly failed over to the second queue manager when the first went down but each queue manager has itÂ´s own set of messages. If more clients were to be connected the connections will get load balanced across all queue managers. Unifom clusters provide scaling/load balacing and continuos avaibility for new transactions. It can be combined with MQ Native HA so that data HA is provided as well. In that case each of the members of the Uniform cluster will have 2 additional passive pods.\n\n## Congratulations\n\nYou have completed this lab for MQ Uniform clusters on CP4I.\n\n## Chalenge\n\nCombine all 3 MQ labs: Add Native HA to the Uniform Cluster members and configure OCP routes and TLS for each of the queue managers.\n","fileAbsolutePath":"/Users/thomas/Documents/IBM/Projects/Internal/techjam/src/pages/mq/2023_Lab4/index.md"}}},
    "staticQueryHashes": ["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}