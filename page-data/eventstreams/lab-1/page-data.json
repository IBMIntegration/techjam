{
    "componentChunkName": "component---src-pages-eventstreams-lab-1-index-md",
    "path": "/eventstreams/lab-1/",
    "result": {"pageContext":{"frontmatter":{"title":"Getting Started with IBM Event Streams 10.5.0"},"relativePagePath":"/eventstreams/lab-1/index.md","titleType":"page","MdxNode":{"id":"b4e8ea4c-83d5-5cfc-aa3e-1eaa604fb99f","children":[],"parent":"cfdf97ef-d191-5df0-b411-30a3cd3301e6","internal":{"content":"---\ntitle: Getting Started with IBM Event Streams 10.5.0\n---\n\n## Introduction\n\nIBM Event Streams is based on years of operational expertise that IBM has gained from running Apache Kafka® for enterprises. IBM Event Streams offers enterprise-grade security, scalability, and reliability running on Red Hat® OpenShift® Container Platform as certified container software. Building an event-driven architecture with IBM Event Streams allows organizations to transition from traditional monolith systems and silos to modern micro-services and event streaming applications that increase their agility and accelerate their time to innovation.\nIBM Event Streams builds on top of open-source Apache Kafka® to offer enterprise-grade event streaming capabilities. The following features are included as part of IBM Event Streams:  \n- Identity and Access Management (IAM) offers fine-grain security controls to manage the access that you want to grant each user for Kafka clusters, Topics, Consumer Groups, Producers, and more.\n- Geo-replication enables the deployment of multiple Event Stream instances in different locations and the synchronization of data between your clusters to improve service availability.\n- Visual driven management and monitoring experience with the Event Streams dashboard that displays metrics collected from the cluster, Kafka brokers, messages, consumers, and producers to provide health check information and options to resolve issues.\n  \nIBM Event Streams enables you to adopt event-driven architectures.\n\n## Lab Objective\n\nThe objective of this lab is to demonstrate the step-by-step process to download and install our Starter Apache Kafka application. The starter application provides a demonstration of a Java application that uses the Vert.x Kafka Client to send and receive events from Event Streams. \n\nThe starter application also includes a user interface to easily view message propagation. The source code is provided in GitHub to allow you to understand the elements required to create your own Kafka application.\nApp details: https://ibm.github.io/event-streams/getting-started/generating-starter-app/\n\nNote: The API keys generated for the starter application can only be used to connect to the topic selected during generation. In addition, the consumer API key can only be used to connect with a consumer group ID set to the name of the generated application.\n\n## Environment used for this lab\n\n1.\tIBM Cloud Pak for Integration \n2.\tRed Hat Openshift Container Platform\n3.\tIBM Event Streams version 10.5.0\n4.\tApache Kafka 2.8.1\n5.\tJava version 8 or 11\n\n## Lab Environment Pre-Requisites\n\n•\tThe Cloud Pak for Integration has been deployed and the access credentials are available.\n•\tJava version 8 installed on local environment.\n•\tApache Maven Installed on local environment.\n\n## Getting started with IBM Event Streams\n\n1. Log into your Event Streams instance using the student credentials provided. Once you've logged in, you'll see the Event Streams homepage.  \n   ![](images/es-eem1.png) \n   \n2. Select “Try the starter application” tile.\n    ![](images/es-eem1a.png)\n3. Create a working directory on your local drive then select the “Download JAR from GitHub” tab. You’ll want the demo-all.jar file for release 1.1.3.\n   ![](images/es-eem2.png)\n4. Copy the downloaded .jar file to your working directory.\n   ![](images/es-eem2a.png)\n5.\tNow let’s generate and download our properties file. Select the “Generate properties” tab. \n    ![](images/es-eem3.png)\n6.\tEnter a name of your app. For guidance, the prefix should be your login ID similar to the example below (i.e. cody1app). This will help us identify which apps are running and who is the owner. Select the “New topic” tab and enter a topic name. Again, use your login ID as the prefix for your topic name. Now select the “Generate and download .zip” tab.\n    ![](images/es-eem4.png)\n7.\tExtract the downloaded .zip file in your working directory. Copy the properties file and p12 file to your working directory. \n    ![](images/es-eem5.png)\n8.\tOpen a terminal and navigate to your working directory. Enter the following command:\njava -Dproperties_path=./ -jar demo-all.jar\n    ![](images/es-eem6.png)\n         \t\n9.\tAfter your applications starts, open a browser, and enter:\nlocalhost:8080 \n    ![](images/es-eem7.png)\n10.\tSelect the “Start Producing” and “Start Consuming” tabs. \n    ![](images/es-eem8.png)\n11.\tYou should soon see messages being produced and consumed.  \n    ![](images/es-eem9.png)\n12.\tNow, let’s check our Event Streams cluster to verify our topic creation and monitoring of the messages. To do this, go back to the Event Streams homepage. Select “Toolbox”.\n    ![](images/es-eem10.png)\n13.\tSelect “Home” to go to the EventStreams homepage.\n    ![](images/es-eem11.png)\n14.\tSelect “Topics” to see the topic you created in the Starter application. Click on your topic to see the Producers, Messages and Consumers.\n    ![](images/es-eem12.png)\n\n**Congratulations! You have successfully run your starter application.**\n\n## Learning summary\n\nIn summary, you have learned the following in this lab:\n- Run an Apache Kafka Java application that has both a producer and consumer.\n- View consumer and producer message traffic in IBM Event Streams console.\n- Specifying the topic within IBM Event Streams and then connecting an Apache Kafka application to produce and consume messages to and from that topic.\n\n","type":"Mdx","contentDigest":"31af36771ddf78359ae2616bfbb551b8","owner":"gatsby-plugin-mdx","counter":1453},"frontmatter":{"title":"Getting Started with IBM Event Streams 10.5.0"},"exports":{},"rawBody":"---\ntitle: Getting Started with IBM Event Streams 10.5.0\n---\n\n## Introduction\n\nIBM Event Streams is based on years of operational expertise that IBM has gained from running Apache Kafka® for enterprises. IBM Event Streams offers enterprise-grade security, scalability, and reliability running on Red Hat® OpenShift® Container Platform as certified container software. Building an event-driven architecture with IBM Event Streams allows organizations to transition from traditional monolith systems and silos to modern micro-services and event streaming applications that increase their agility and accelerate their time to innovation.\nIBM Event Streams builds on top of open-source Apache Kafka® to offer enterprise-grade event streaming capabilities. The following features are included as part of IBM Event Streams:  \n- Identity and Access Management (IAM) offers fine-grain security controls to manage the access that you want to grant each user for Kafka clusters, Topics, Consumer Groups, Producers, and more.\n- Geo-replication enables the deployment of multiple Event Stream instances in different locations and the synchronization of data between your clusters to improve service availability.\n- Visual driven management and monitoring experience with the Event Streams dashboard that displays metrics collected from the cluster, Kafka brokers, messages, consumers, and producers to provide health check information and options to resolve issues.\n  \nIBM Event Streams enables you to adopt event-driven architectures.\n\n## Lab Objective\n\nThe objective of this lab is to demonstrate the step-by-step process to download and install our Starter Apache Kafka application. The starter application provides a demonstration of a Java application that uses the Vert.x Kafka Client to send and receive events from Event Streams. \n\nThe starter application also includes a user interface to easily view message propagation. The source code is provided in GitHub to allow you to understand the elements required to create your own Kafka application.\nApp details: https://ibm.github.io/event-streams/getting-started/generating-starter-app/\n\nNote: The API keys generated for the starter application can only be used to connect to the topic selected during generation. In addition, the consumer API key can only be used to connect with a consumer group ID set to the name of the generated application.\n\n## Environment used for this lab\n\n1.\tIBM Cloud Pak for Integration \n2.\tRed Hat Openshift Container Platform\n3.\tIBM Event Streams version 10.5.0\n4.\tApache Kafka 2.8.1\n5.\tJava version 8 or 11\n\n## Lab Environment Pre-Requisites\n\n•\tThe Cloud Pak for Integration has been deployed and the access credentials are available.\n•\tJava version 8 installed on local environment.\n•\tApache Maven Installed on local environment.\n\n## Getting started with IBM Event Streams\n\n1. Log into your Event Streams instance using the student credentials provided. Once you've logged in, you'll see the Event Streams homepage.  \n   ![](images/es-eem1.png) \n   \n2. Select “Try the starter application” tile.\n    ![](images/es-eem1a.png)\n3. Create a working directory on your local drive then select the “Download JAR from GitHub” tab. You’ll want the demo-all.jar file for release 1.1.3.\n   ![](images/es-eem2.png)\n4. Copy the downloaded .jar file to your working directory.\n   ![](images/es-eem2a.png)\n5.\tNow let’s generate and download our properties file. Select the “Generate properties” tab. \n    ![](images/es-eem3.png)\n6.\tEnter a name of your app. For guidance, the prefix should be your login ID similar to the example below (i.e. cody1app). This will help us identify which apps are running and who is the owner. Select the “New topic” tab and enter a topic name. Again, use your login ID as the prefix for your topic name. Now select the “Generate and download .zip” tab.\n    ![](images/es-eem4.png)\n7.\tExtract the downloaded .zip file in your working directory. Copy the properties file and p12 file to your working directory. \n    ![](images/es-eem5.png)\n8.\tOpen a terminal and navigate to your working directory. Enter the following command:\njava -Dproperties_path=./ -jar demo-all.jar\n    ![](images/es-eem6.png)\n         \t\n9.\tAfter your applications starts, open a browser, and enter:\nlocalhost:8080 \n    ![](images/es-eem7.png)\n10.\tSelect the “Start Producing” and “Start Consuming” tabs. \n    ![](images/es-eem8.png)\n11.\tYou should soon see messages being produced and consumed.  \n    ![](images/es-eem9.png)\n12.\tNow, let’s check our Event Streams cluster to verify our topic creation and monitoring of the messages. To do this, go back to the Event Streams homepage. Select “Toolbox”.\n    ![](images/es-eem10.png)\n13.\tSelect “Home” to go to the EventStreams homepage.\n    ![](images/es-eem11.png)\n14.\tSelect “Topics” to see the topic you created in the Starter application. Click on your topic to see the Producers, Messages and Consumers.\n    ![](images/es-eem12.png)\n\n**Congratulations! You have successfully run your starter application.**\n\n## Learning summary\n\nIn summary, you have learned the following in this lab:\n- Run an Apache Kafka Java application that has both a producer and consumer.\n- View consumer and producer message traffic in IBM Event Streams console.\n- Specifying the topic within IBM Event Streams and then connecting an Apache Kafka application to produce and consume messages to and from that topic.\n\n","fileAbsolutePath":"/Users/thomas/Documents/IBM/Projects/Internal/techjam/src/pages/eventstreams/lab-1/index.md"}}},
    "staticQueryHashes": ["1364590287","137577622","2102389209","2456312558","2746626797","3018647132","3037994772","768070550"]}